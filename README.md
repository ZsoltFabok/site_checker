###Site Checker [![Code Climate](https://codeclimate.com/badge.png)](https://codeclimate.com/github/ZsoltFabok/site_checker) [![Build Status](https://travis-ci.org/ZsoltFabok/site_checker.png)](https://travis-ci.org/ZsoltFabok/site_checker)

Site Checker is a simple ruby gem, which helps you check the integrity of your website by recursively visiting the referenced pages and images. I use it in my test environments to make sure that my websites don't have any dead links.

### Install

`gem install site_checker`

### Usage

First, you have to load the `site_checker` by adding this line to the file where you would like to use it:

`require 'site_checker'`

If you want to use it for testing, the line should goto the `test_helper.rb`.

The usage is quite simple:

```ruby
site_checker = SiteChecker.new
site_checker.check("http://localhost:3000/app", "http://localhost:3000")
puts site_checker.remote_pages.inspect
puts site_checker.local_pages.inspect
puts site_checker.remote_images.inspect
puts site_checker.local_images.inspect
puts site_checker.problems.inspect
```

The snippet above will open the `http://localhost:3000/app` link and will look for links and images. If it finds a link to a local page, it will recursively checkout out that page, too. The second argument - `http://localhost:3000` - defines the starting reference of your website.

### Using on Generated Content
If you have a static website (e.g. generated by [octopress](https://github.com/imathis/octopress)) you can tell `site_checker` to use folders from the file system. With this approach, you don't need a webserver for verifying your website:

```ruby
site_checker = SiteChecker.new
site_checker.check("./public", "./public")
puts site_checker.problems.inspect
```

### Configuration
You can instruct `site_checker` to ignore certain links:

```ruby
site_checker = SiteChecker.new do |s|
  s.ignore_list = ["/", "/atom.xml"]
end
```

By default it won't check the conditions of the remote links and images - e.g. 404 or 500 -, but you can change it like this:

```ruby
site_checker = SiteChecker.new do |s|
  s.visit_references = true
end
```

Too deep recursive calls may be expensive, so you can configure the maximum depth of the recursion with the following attribute:

```ruby
site_checker = SiteChecker.new do |s|
  s.max_recursion_depth = 3
end
```

### Examples
Make sure that there are no local dead links on the website (I'm using [rspec](https://github.com/rspec/rspec) syntax):
```ruby
before(:each) do
  @site_checker = SiteChecker.new do |s|
    s.ignore_list = ["/atom.xml", "/rss"]
  end
end

it "should not have dead local links" do
  @site_checker.check("http://localhost:3000", "http://localhost:3000")
  # this will print out the difference and I don't have to re-run with print
  @site_checker.problems.should eql({})
end
```

Check that all the local pages can be reached with maximum two steps:

```ruby
before(:each) do
  @site_checker = SiteChecker.new do |s|
    s.ignore_list = ["/atom.xml", "/rss"]
    s.max_recursion_depth = 2
  end

  @number_of_local_pages = 100
end

it "all the local pages have to be visited" do
  @site_checker.check("http://localhost:3000", "http://localhost:3000")
  @site_checker.local_pages.size.should eq @number_of_local_pages
end
```

### Copyright

Copyright (c) 2012 Zsolt Fabok and Contributors. See LICENSE for details.
